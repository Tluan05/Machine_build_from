# ==============================
# ğŸ“¦ 1. Import thÆ° viá»‡n
# ==============================
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# ==============================
# âš™ï¸ 2. CÃ i Ä‘áº·t SVM thá»§ cÃ´ng
# ==============================
class SVM:
    def __init__(self, learning_rate=0.001, lambda_param=0.01, n_iters=1000):
        self.lr = learning_rate
        self.lambda_param = lambda_param
        self.n_iters = n_iters
        self.w = None
        self.b = None

    def fit(self, X, y):
        # Äáº£m báº£o X lÃ  máº£ng numpy dense
        X = np.array(X)
        n_samples, n_features = X.shape
        y_ = np.where(y <= 0, -1, 1)
        self.w = np.zeros(n_features)
        self.b = 0

        for _ in range(self.n_iters):
            idxs = np.random.permutation(n_samples)
            for idx in idxs:
                x_i = X[idx]
                condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >= 1
                if condition:
                    self.w -= self.lr * (2 * self.lambda_param * self.w)
                else:
                    self.w -= self.lr * (2 * self.lambda_param * self.w - y_[idx] * x_i)
                    self.b -= self.lr * y_[idx]

    def predict(self, X):
        X = np.array(X)
        approx = np.dot(X, self.w) - self.b
        return np.where(approx >= 0, 1, 0)

# ==============================
# ğŸ“‚ 3. Äá»c dá»¯ liá»‡u
# ==============================
data = pd.read_csv("spam_ham.csv", encoding='latin-1')

# MÃ£ hÃ³a nhÃ£n
data['label_num'] = data['label'].map({'Ham': 0, 'Spam': 1})

# ==============================
# ğŸ§  4. TÃ¡ch train/test vÃ  vector hÃ³a TF-IDF
# ==============================
X = data['text']
y = data['label_num']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)

vectorizer = TfidfVectorizer(stop_words='english', max_features=500)
X_train_vec = vectorizer.fit_transform(X_train).toarray()
X_test_vec = vectorizer.transform(X_test).toarray()

# ==============================
# ğŸš€ 5. Huáº¥n luyá»‡n mÃ´ hÃ¬nh
# ==============================
model = SVM(learning_rate=0.001, n_iters=200, lambda_param=0.01)
model.fit(X_train_vec, y_train)

# ==============================
# ğŸ” 6. Dá»± Ä‘oÃ¡n vÃ  Ä‘Ã¡nh giÃ¡
# ==============================
y_pred = model.predict(X_test_vec)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print("===== ÄÃNH GIÃ MÃ” HÃŒNH SVM THá»¦ CÃ”NG =====")
print(f"Accuracy : {accuracy:.4f}")
print(f"Precision: {precision:.4f}")
print(f"Recall   : {recall:.4f}")
print(f"F1-score : {f1:.4f}")

# ==============================
# ğŸ“Š 7. Ma tráº­n nháº§m láº«n
# ==============================
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5, 4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel("Predicted Labels")
plt.ylabel("True Labels")
plt.title("Confusion Matrix - Custom SVM")
plt.show()
